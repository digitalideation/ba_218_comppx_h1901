{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "To run this code you will need to install [Matplotlib](https://matplotlib.org/users/installing.html) and [Numpy](https://www.scipy.org/install.html)\n",
    "\n",
    "If you like to run the example locally follow the instructions provided on [Keras website](https://keras.io/#installation)\n",
    "\n",
    "It's __strongly__ suggested to use a Python environments manager such as [Conda](https://conda.io/docs/) or some kind of [VirutalEnv](#)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing CNN on our shape classifier\n",
    "\n",
    "Let's try to use a CNN to improve our shape classification model.\n",
    "\n",
    "We create the dataset _manually_ as we did before. By drawing the shapes with the `draw_shape` function that generat some random shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 0 = rectangle, 1 = triangle, 2 = ellipse\n",
    "# return shape\n",
    "def draw_shape(max_size, type):\n",
    "    \n",
    "    # Random size and fixed coordinate\n",
    "#     s = math.floor(random.randrange(1, max_size-4))\n",
    "#     x = math.floor(max_size/2)\n",
    "#     y = math.floor(max_size/2)\n",
    "\n",
    "    # Not so random size and random coordinate\n",
    "    s = int(random.randrange(max_size/2, max_size))\n",
    "    x = int(random.randrange(int(s/2), max_size-int(s/2)))\n",
    "    y = int(random.randrange(int(s/2), max_size-int(s/2)))\n",
    "\n",
    "    type = type%3\n",
    "    \n",
    "    if type == 0:\n",
    "        art = plt.Rectangle((x-s/2, y-s/2), s, s, color='r')\n",
    "\n",
    "    if type == 1:\n",
    "        verts = [\n",
    "            (x-s/2, y-s/2),\n",
    "            (x, y+s/2),\n",
    "            (x+s/2, y-s/2)\n",
    "        ]\n",
    "        art = plt.Polygon(verts, color='r')\n",
    "\n",
    "    if type == 2:\n",
    "        art = plt.Circle((x, y), s/2, color='r')\n",
    "    \n",
    "    return art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a helper function that convert a matplotlib figure to a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/7821917\n",
    "def fig2rgb_array(fig):\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.tostring_rgb()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    return np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function see if it works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAD8AAAA8CAYAAADRy2JxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAHYQAAB2EBlcO4tgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAAipJREFUaIHtmrFqFFEUhr8/KCS+gos7liK4TSpLWbAIgu3aCIKijYUia5VOyBQiaUQIBDWFgmATUgh5hYDVgt2IUXwAwRTCsUgGdM3MzmbvnRXO/eAUy549/D/33j3DnCszwysL8xYwT5J5ryTzXknmvXIqVKHBYGDdbjdUuSDkef7GzG5UJphZkBgOh/a/AaxZjWbX2z6Z90oy75Vgre4vVlagKKKUnkiWwc5Oo9Q45osCRqMopUPietsn815J5r2SzI8j6ZqkDUnvJF2U9EnSC0nX2xYYk2P7vJltA9uSesBV4AdwBthvUVt0Kre9pAXgHvAWWAbuAA9b0tUKVdtewFNgw8y+Hb0bOAD+Ge9I6ktaK+b1ODsDVSt/H7gM3Jb0SNKmpC3g/Xiime2a2eMsyyLKjEPVmV8H1lvW0jqp1XklmfdKMu+VZN4rybxXknmvJPOTkNSRtHUUl2KLaoumK38LWOXwbc7deHLapems7izwxcx+SVqMKahNmpr/CnQkfQcO/vxCUh/oAx/zPP8QSFcX+HyiX45GIJWfztXm1l3YKQPoAK+Al0CvIqf28s80EbJWXTRaeTPbB25OSNttUqshIWtVIkv37U9OqDY4lylRgPO5CpwHloDnAer1gAfAHvAaWI515kM84ZVt8CcwUxtse0oUwnzZBhcZa4PTMM2UKBQhLiRtAk84FPlshjrllGhJ0hXgAnCaY6ZEoUj/9l5J5r2SzHvlN1HzrShDKrCdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 48x48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image and dataset size we are going to use\n",
    "image_size = 48\n",
    "dataset_size = 5000\n",
    "\n",
    "# Create plot's figure and axes\n",
    "# https://stackoverflow.com/a/638443\n",
    "fig = plt.figure(figsize=(1,1), dpi=image_size)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Setting for the axes\n",
    "ax.set_xlim(0,image_size)\n",
    "ax.set_ylim(0,image_size)\n",
    "# ax.axis('off')\n",
    "\n",
    "# Draw a random shape\n",
    "art = draw_shape(image_size,random.randint(0,2))\n",
    "# Add the shape to the plot\n",
    "# https://stackoverflow.com/a/29184075\n",
    "plt.gcf().gca().add_artist(art)\n",
    "# gcf() means Get Current Figure\n",
    "# gca() means Get Current Axis\n",
    "\n",
    "# convert the figure to an array\n",
    "data = fig2rgb_array(fig)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a loop that will generate a small dataset for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 48, 48, 3)\n",
      "(5000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADsAAAA4CAYAAABDsYAdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAHYQAAB2EBlcO4tgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAAelJREFUaIHtms1KW0EYhp/XRI3RkEJFxHPQrZfRTaVuxFVx489C3Kgbs5AgIqJS2rrp3fQSeiHehqSL6YFUjCfnnPmBcZ5dyHzzzXNeZk4GotFoxHthJvQCfJJkYyXJxkqSjZUkGytJNlaSbKwkWe9IX5D+IMllm/CyRvAHsAl8dtkqvCzsAutAH/jpMt2wskbsASMKsAHsuGoXOtk9IB/73AceXKUbTlZqATdA78U368BXFy1DJnvI/6kW9IBbJOtrCyMrtYEhsDhhRAbs224bKtkTjNAkloCrfw/FGv5lpTngAlgoGZkBxzZbh0j2jLdTLegCA6RZW439ykodjGxnyoocOLXV3neyA6ZLtaADnCPN22juT1bqYvbgXMXKDLPHG+Mz2SGvv1fLmAdOkMoOtFL8yEo94ACo+yrJgMumy/CV7A3V9upLZoEjpKUmi3AvK33A/NZtNZwpA66bTOAj2XuapVrQBvaQ+qUjJ+BWVlrG3E9t9cmBu7rFrpP9Tr0TeBIzwC7Sx7rFbpBWgS3A9kU8B77VKXSZ7CN2Uy0QsI20UrXQjayUA5+czG3IMQ+zEq6S/YWdE/gttpHWqhRYvRyP8Rt4cjT3OM9VBiv96StSkmysJNlYSbKxkmRjJcnGSpKNlXcl+xcr/yLU0nak2QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 48x48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_dataset(image_size, dataset_size):\n",
    "\n",
    "    # Those variable will contain the images and associated labels\n",
    "    images = np.zeros((dataset_size, image_size, image_size, 3))\n",
    "    labels = np.zeros((dataset_size))\n",
    "    \n",
    "    # The plot figure we will use to generate the shapes\n",
    "    fig = plt.figure(figsize=(1,1), dpi=image_size)\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        \n",
    "        # Clear the figure\n",
    "        fig.clf()\n",
    "        \n",
    "        # Recreate the axes\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_xlim(0, image_size)\n",
    "        ax.set_ylim(0, image_size)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Define label\n",
    "        label = i%3\n",
    "        art = draw_shape(image_size, label)\n",
    "        plt.gcf().gca().add_artist(art)\n",
    "        \n",
    "        # Add values to the arrays\n",
    "        images[i] = fig2rgb_array(fig)\n",
    "        labels[i] = label\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "# Generate our dataset\n",
    "images, labels = generate_dataset(image_size, dataset_size)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we can save our dataset for later, since it takes quite some time to generate it ðŸ˜‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('datasets/shape-example-shapes4.npy', images)\n",
    "# np.save('datasets/shape-example-labels1.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to load it we can then use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('datasets/shape-example-shapes1.npy')\n",
    "labels = np.load('datasets/shape-example-labels1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset manually in training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 48, 48, 3)\n",
      "(4000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f50810b7358>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the size of the training set, here we use 80% of the total samples for training\n",
    "train_size = int(dataset_size*.8)\n",
    "\n",
    "# TODO: We should shuffle the dataset\n",
    "\n",
    "# Split the dataset into train and test dataset\n",
    "train_images, test_images = images[:train_size], images[train_size:]\n",
    "train_labels, test_labels = labels[:train_size], labels[train_size:]\n",
    "\n",
    "# Verify the data\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# sample_images = []\n",
    "# for label, image in list(zip(train_labels, train_images))[:10]:\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.axis('off')\n",
    "#     plt.title(label)\n",
    "#     fig1.add_subplot(111).imshow(image/255)\n",
    "\n",
    "full_image = np.concatenate(train_images[:12]/255, axis=1)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(full_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), \n",
    "                       activation='relu', input_shape=(image_size, image_size, 3)))\n",
    "network.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "network.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "network.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(1000, activation='relu'))\n",
    "network.add(layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the `[0, 1]` interval. Then we also need to categorically encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 48, 48, 3)\n",
      "(1000, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "print(train_images.shape)\n",
    "test_images = test_images.astype('float32') / 255\n",
    "print(test_images.shape)\n",
    "\n",
    "# Encode to categorical\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.4586e-04 - acc: 1.0000\n",
      "Epoch 2/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.2577e-04 - acc: 1.0000\n",
      "Epoch 3/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.0878e-04 - acc: 1.0000\n",
      "Epoch 4/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 1.0029e-04 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 8.5403e-05 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 8.7223e-05 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 6.6778e-05 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 6.0186e-05 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 5.7279e-05 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 4.9531e-05 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 4.5208e-05 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 4.2180e-05 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 3.9745e-05 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 3.5040e-05 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 3.2611e-05 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 3.0067e-05 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 2.8369e-05 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 2.5711e-05 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 2.4069e-05 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 2.2819e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5090ca2128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=20, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 510us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "# get_image will return a handle to the image itself, and a numpy array of its pixels to input the network\n",
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=network.input_shape[1:3])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, x = get_image(\"assets/photo_rect_red01.jpg\")\n",
    "predictions = network.predict(x)\n",
    "plt.imshow(img)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try adding data augmentation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
